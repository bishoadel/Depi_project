import gradio as gr
import torch
from diffusers import DiffusionPipeline

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ---
MODEL_PATH = "./sd-model-advanced"
device = "cuda" if torch.cuda.is_available() else "cpu"

print(f"â³ Loading Model on {device}... (This may take a moment)")

try:
    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø±Ø¨
    pipe = DiffusionPipeline.from_pretrained(MODEL_PATH, torch_dtype=torch.float16)
    pipe.to(device)
    status_msg = "âœ… Using Your Finetuned Model (COCO 2017)"
except Exception as e:
    print(f"âš ï¸ Error loading finetuned model: {e}")
    print("âš ï¸ Switching to Base Model for demo purposes...")
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø£ØµÙ„ÙŠ ÙƒØ¨Ø¯ÙŠÙ„
    pipe = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)
    pipe.to(device)
    status_msg = "âš ï¸ Using Base Model (Training might not be fully saved yet)"

# --- 2. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ ---
def generate_image(prompt, negative_prompt, steps, guidance):
    if not prompt:
        return None
    
    # Ø§Ù„ØªÙˆÙ„ÙŠØ¯
    image = pipe(
        prompt, 
        negative_prompt=negative_prompt, 
        num_inference_steps=int(steps), 
        guidance_scale=guidance
    ).images[0]
    
    return image

# --- 3. ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ© Ø§Ù„Ù…Ø¶Ù…ÙˆÙ†Ø©) ---
# Ø£Ø²Ù„Ù†Ø§ Ø£ÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„Ù„Ø«ÙŠÙ…Ø§Øª Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø£ÙŠ Ø¥ØµØ¯Ø§Ø±
with gr.Blocks() as demo:
    gr.Markdown("# ğŸ¨ DEPI Generative AI Project")
    gr.Markdown(f"### {status_msg}")
    
    with gr.Row():
        with gr.Column():
            # Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
            txt_prompt = gr.Textbox(label="Enter your prompt", placeholder="e.g., a futuristic city on mars...", lines=2)
            txt_negative = gr.Textbox(label="Negative Prompt", value="low quality, blurry, distorted", lines=1)
            
            # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
            with gr.Accordion("Advanced Settings", open=False):
                slider_steps = gr.Slider(minimum=10, maximum=100, value=50, step=1, label="Inference Steps")
                slider_guidance = gr.Slider(minimum=1, maximum=20, value=7.5, step=0.5, label="Guidance Scale")
            
            # Ø²Ø± Ø§Ù„ØªØ´ØºÙŠÙ„
            btn_generate = gr.Button("ğŸš€ Generate Image")
            
        with gr.Column():
            # Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
            output_img = gr.Image(label="Generated Result", type="pil")

    # Ø±Ø¨Ø· Ø§Ù„Ø²Ø± Ø¨Ø§Ù„Ø¯Ø§Ù„Ø©
    btn_generate.click(generate_image, inputs=[txt_prompt, txt_negative, slider_steps, slider_guidance], outputs=output_img)

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if __name__ == "__main__":
    print("ğŸŒ Starting Web UI...")
    demo.launch(share=True)