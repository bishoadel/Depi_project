import os
import torch
import torch.nn.functional as F
from accelerate import Accelerator
from datasets import load_dataset
from diffusers import DDPMScheduler, UNet2DConditionModel, DiffusionPipeline, AutoencoderKL
from diffusers.optimization import get_scheduler
from transformers import CLIPTextModel, CLIPTokenizer
from torchvision import transforms
from tqdm.auto import tqdm
import logging
import math

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… ---
MODEL_NAME = "runwayml/stable-diffusion-v1-5"
OUTPUT_DIR = "./sd-model-advanced"  # Ø³Ù†Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙÙŠ Ù…Ø¬Ù„Ø¯ Ù…Ù†ÙØµÙ„
DATA_DIR = "./processed_coco_final" # Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¶Ø®Ù… Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ

# --- Hyperparameters ---
TRAIN_BATCH_SIZE = 6    # Ø±ÙØ¹Ù†Ø§ Ø§Ù„Ø¨Ø§ØªØ´ Ù„Ø§Ø³ØªØºÙ„Ø§Ù„ Ø§Ù„Ù€ 24GB VRAM
GRADIENT_ACCUMULATION_STEPS = 1
LEARNING_RATE = 1e-5
NUM_EPOCHS = 3          # 3 Ø¯ÙˆØ±Ø§Øª ÙƒØ§Ù…Ù„Ø© (Ø¬ÙˆØ¯Ø© Ø¹Ø§Ù„ÙŠØ©)
LR_SCHEDULER = "cosine" # Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù… ØªØ¯Ø±ÙŠØ¬ÙŠØ§Ù‹
LR_WARMUP_STEPS = 500

# ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø£Ø¯ÙˆØ§Øª (Global for Windows Fix)
tokenizer = CLIPTokenizer.from_pretrained(MODEL_NAME, subfolder="tokenizer")

# --- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Augmentation) ---
# Ø¥Ø¶Ø§ÙØ© RandomHorizontalFlip Ù„Ø²ÙŠØ§Ø¯Ø© ØªÙ†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
train_transforms = transforms.Compose([
    transforms.Resize(512, interpolation=transforms.InterpolationMode.BILINEAR),
    transforms.CenterCrop(512),
    transforms.RandomHorizontalFlip(p=0.5), 
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5]),
])

def preprocess_train(examples):
    images = [train_transforms(image.convert("RGB")) for image in examples["image"]]
    text_inputs = tokenizer(
        examples["text"], padding="max_length", max_length=tokenizer.model_max_length, truncation=True, return_tensors="pt"
    )
    return {"pixel_values": images, "input_ids": text_inputs.input_ids}

def main():
    # 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø±Ø¹
    accelerator = Accelerator(
        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,
        mixed_precision="fp16"
    )

    logging.basicConfig(format="%(asctime)s - %(levelname)s - %(message)s", level=logging.INFO)

    if accelerator.is_main_process:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        print("\n" + "="*50)
        print(f"ğŸš€ STARTING ADVANCED TRAINING (Epochs: {NUM_EPOCHS})")
        print(f"ğŸ“‚ Dataset: {DATA_DIR} (126k Images)")
        print(f"ğŸ§  Scheduler: {LR_SCHEDULER} | Augmentation: ON")
        print("="*50 + "\n")

    # 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª
    noise_scheduler = DDPMScheduler.from_pretrained(MODEL_NAME, subfolder="scheduler")
    text_encoder = CLIPTextModel.from_pretrained(MODEL_NAME, subfolder="text_encoder")
    vae = AutoencoderKL.from_pretrained(MODEL_NAME, subfolder="vae")
    unet = UNet2DConditionModel.from_pretrained(MODEL_NAME, subfolder="unet")

    # ØªÙØ¹ÙŠÙ„ Gradient Checkpointing Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù…Ø¹ Ø§Ù„Ø¨Ø§ØªØ´ Ø§Ù„ÙƒØ¨ÙŠØ±
    unet.enable_gradient_checkpointing()

    vae.requires_grad_(False)
    text_encoder.requires_grad_(False)
    unet.train()

    # 3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if accelerator.is_main_process:
        print("â³ Loading Ultimate Dataset...")
        
    dataset = load_dataset("imagefolder", data_dir=DATA_DIR, split="train")
    
    with accelerator.main_process_first():
        train_dataset = dataset.with_transform(preprocess_train)

    train_dataloader = torch.utils.data.DataLoader(
        train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=2
    )

    optimizer = torch.optim.AdamW(unet.parameters(), lr=LEARNING_RATE)

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø·ÙˆØ§Øª ÙˆØ§Ù„Ù€ Scheduler
    num_update_steps_per_epoch = math.ceil(len(train_dataloader) / GRADIENT_ACCUMULATION_STEPS)
    max_train_steps = NUM_EPOCHS * num_update_steps_per_epoch

    lr_scheduler = get_scheduler(
        LR_SCHEDULER,
        optimizer=optimizer,
        num_warmup_steps=LR_WARMUP_STEPS * accelerator.num_processes,
        num_training_steps=max_train_steps,
    )

    # Ø§Ù„ØªØ­Ø¶ÙŠØ±
    unet, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
        unet, optimizer, train_dataloader, lr_scheduler
    )
    
    text_encoder.to(accelerator.device, dtype=torch.float16)
    vae.to(accelerator.device, dtype=torch.float16)

    # 4. Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    if accelerator.is_main_process:
        print(f"âœ… Ready! Total Optimization Steps: {max_train_steps}")
        print("ğŸš€ Training Started... (This will take hours, monitor your GPU temps!)")

    global_step = 0
    progress_bar = tqdm(range(max_train_steps), disable=not accelerator.is_local_main_process, desc="Advanced Training", unit="step")

    for epoch in range(NUM_EPOCHS):
        unet.train()
        train_loss = 0.0
        for step, batch in enumerate(train_dataloader):
            with accelerator.accumulate(unet):
                latents = vae.encode(batch["pixel_values"].to(dtype=torch.float16)).latent_dist.sample()
                latents = latents * vae.config.scaling_factor
                
                noise = torch.randn_like(latents)
                bsz = latents.shape[0]
                timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device).long()
                
                noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)
                encoder_hidden_states = text_encoder(batch["input_ids"])[0]
                
                model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample
                loss = F.mse_loss(model_pred.float(), noise.float(), reduction="mean")
                
                accelerator.backward(loss)
                optimizer.step()
                lr_scheduler.step()
                optimizer.zero_grad()
                
                train_loss += loss.detach().item()

            if accelerator.sync_gradients:
                progress_bar.update(1)
                global_step += 1
                progress_bar.set_postfix({"loss": f"{train_loss / (step + 1):.4f}"})

        # Ø­ÙØ¸ Ù†Ø³Ø®Ø© (Checkpoint) Ø¨Ø¹Ø¯ ÙƒÙ„ Epoch
        if accelerator.is_main_process:
            epoch_save_path = os.path.join(OUTPUT_DIR, f"checkpoint-epoch-{epoch+1}")
            print(f"\nğŸ’¾ Saving Checkpoint for Epoch {epoch+1}...")
            pipeline = DiffusionPipeline.from_pretrained(
                MODEL_NAME,
                unet=accelerator.unwrap_model(unet),
                text_encoder=text_encoder,
                vae=vae,
                tokenizer=tokenizer,
            )
            pipeline.save_pretrained(epoch_save_path)

    # Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    if accelerator.is_main_process:
        pipeline.save_pretrained(OUTPUT_DIR)
        print("\n" + "="*50)
        print(f"ğŸ‰ ADVANCED TRAINING COMPLETE!")
        print(f"ğŸ“‚ Final Model: {os.path.abspath(OUTPUT_DIR)}")
        print("="*50)

if __name__ == "__main__":
    main()